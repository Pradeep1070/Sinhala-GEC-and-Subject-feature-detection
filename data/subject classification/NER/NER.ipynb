{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "#from sklearn.naive_bayes import CategoricalNB\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC #, LinearSVC,NuSVC\n",
    "\n",
    "#from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "from pygam import LogisticGAM\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import f1_score,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8ff412",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  glob,os\n",
    "import csv\n",
    "\n",
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a05ab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running Translate API\n",
    "from googleapiclient.discovery import build\n",
    "\n",
    "APIKEY = 'AIzaSyCvizBtXrBHbISVhoKS-08Hr3ymyNbBFvg'\n",
    "service = build('translate', 'v2', developerKey=APIKEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5af36a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isEnglish('reincarnations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize=3 #A centred window of size N around the word to be disambiguated is considered in feature generation.\n",
    "#make sure minimum sen length is =>windowSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4c1e16e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58484 2823\n"
     ]
    }
   ],
   "source": [
    "path='D:\\\\#Data_science\\\\Resesrch\\\\#NLP sinhala Resources\\\\AnanyaSinhalaNERDataset-master\\\\Sinmin+UCSC_Final_69k\\\\'\n",
    "lines1=[]\n",
    "labels1=[]\n",
    "for filename in glob.glob(os.path.join(path, '*.tsv')):\n",
    "   with open(os.path.join(os.getcwd(), filename), 'r') as f: \n",
    "        \n",
    "        tsv_file = open(filename,encoding='utf-8')\n",
    "        read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "        # print(filename)\n",
    "        for row in read_tsv:\n",
    "            if row:\n",
    "                if len(row)==1:\n",
    "                    if row==['.   O']:\n",
    "                        row=['.', 'O']\n",
    "                    else:\n",
    "                        if ' ' in row[0]:\n",
    "                            row[0]=row[0].replace(' ','\\t',1)\n",
    "                            row[0]=row[0].replace(' ','')\n",
    "                            row=row[0].split('\\t')\n",
    "                        # print(row)\n",
    "                if len(row)>2:\n",
    "                    if '' in row:\n",
    "                        row.remove('')\n",
    "                lines1.append(row[0]+' '+row[1])\n",
    "                labels1.append(row[1])\n",
    "print(len(lines1),lines1.count('. O'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb13eec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ORG', 'PER', 'LOC', 'O']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(labels1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "487f5103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42044 1964\n"
     ]
    }
   ],
   "source": [
    "path='D:\\\\#Data_science\\\\Resesrch\\\\#NLP sinhala Resources\\\\AnanyaSinhalaNERDataset-master\\\\NewsPaper_41k\\\\'\n",
    "lines2=[]\n",
    "labels2=[]\n",
    "for filename in glob.glob(os.path.join(path, '*.tsv')):\n",
    "   with open(os.path.join(os.getcwd(), filename), 'r') as f: \n",
    "        \n",
    "        tsv_file = open(filename,encoding='utf-8')\n",
    "        read_tsv = csv.reader(tsv_file, delimiter=\"\\t\")\n",
    "        # print(filename)\n",
    "        for row in read_tsv:\n",
    "            if row:\n",
    "                if len(row)==1:\n",
    "                    if row==['.   O']:\n",
    "                        row=['.', 'O']\n",
    "                    else:\n",
    "                        if ' ' in row[0]:\n",
    "                            row[0]=row[0].replace(' ','\\t',1)\n",
    "                            row[0]=row[0].replace(' ','')\n",
    "                            row=row[0].split('\\t')\n",
    "                        # print(row)\n",
    "                if len(row)>2:\n",
    "                    if '' in row:\n",
    "                        row.remove('')\n",
    "                if row[1]=='O ': row[1]='O'\n",
    "                lines2.append(row[0]+' '+row[1])\n",
    "                labels2.append(row[1])\n",
    "print(len(lines2),lines2.count('. O'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df6cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tags=defaultdict(list)\n",
    "for i in lines1+lines:\n",
    "    tmp=i.split(' ')\n",
    "    tags[tmp[1]].append(tmp[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "7f9ad575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['පි\\u200d්\\u200dරයංකා',\n",
       " 'ගමවල්',\n",
       " 'ගගාරින්',\n",
       " 'සුපුන්',\n",
       " 'හිල්',\n",
       " 'ආරියවංශ',\n",
       " 'බ්ලික්ස්',\n",
       " 'ට්\\u200dරොන්',\n",
       " 'ගිරිජා',\n",
       " 'පලන්සූරිය',\n",
       " 'අමිල',\n",
       " 'හැරිත්',\n",
       " 'මොහමඩ්',\n",
       " 'බි.',\n",
       " 'තාරකාද',\n",
       " 'ධර්මාශෝක',\n",
       " 'අයෝධ්\\u200dයා',\n",
       " 'නොලර්ටිගේ',\n",
       " 'ක්\\u200dරිෂාන්ති',\n",
       " 'ෂැරෝන්ගේ',\n",
       " 'සිලර්',\n",
       " 'රාජ්කුමාරි',\n",
       " 'ජෙකොබ්',\n",
       " 'රුසිත්',\n",
       " 'අමිත',\n",
       " 'පෝලෝ',\n",
       " 'මධුෂාන්',\n",
       " 'කොඩිකාරගේ',\n",
       " 'ඉන්ද්\\u200dරරත්න',\n",
       " 'කීර්තිනන්දගේ',\n",
       " 'ෆොන්සේකා',\n",
       " 'හෙට්ටිගේ',\n",
       " 'ඬේවිඞ්',\n",
       " 'ඕෂනී',\n",
       " 'කලාම්ගේ',\n",
       " 'චරිත',\n",
       " 'යූරී',\n",
       " 'සෝරත',\n",
       " 'මෂාල්',\n",
       " 'ඩි.',\n",
       " 'ඩී.',\n",
       " 'සිවරාමලිංගම්',\n",
       " 'සත්\\u200dයාංගනී',\n",
       " 'ඉලංගරත්න',\n",
       " 'විතාන',\n",
       " 'විරාජ්',\n",
       " 'චරිතානි',\n",
       " 'පෝතාගම',\n",
       " 'කුරුගලගේ',\n",
       " 'ෂැරොන්',\n",
       " 'ඩබ්.',\n",
       " 'ටෙනෙට්',\n",
       " 'මුෂරෆ්',\n",
       " 'ජේම්ස්',\n",
       " 'මාග්\\u200dරට්',\n",
       " 'සුජීව',\n",
       " 'ඉගලෑන්ඩ්',\n",
       " 'යාසින්ගේ',\n",
       " 'ජානකි',\n",
       " 'අමරසේන',\n",
       " 'නාගිත',\n",
       " 'නිසාමුදීන්',\n",
       " 'කිඩ්වා',\n",
       " 'සෙබාරි',\n",
       " 'නිල්මිණි',\n",
       " 'ධම්මානන්ද',\n",
       " 'රබ්බිඩිගලගේ',\n",
       " 'වනිගසූරිය',\n",
       " 'උපාලි',\n",
       " 'කොයිසුමිගේත්',\n",
       " 'දසන්ත',\n",
       " 'අබ්දුල්ලා',\n",
       " 'ටිබෙට්',\n",
       " 'යිංග්ලක්',\n",
       " 'කොලින්ස්',\n",
       " 'ඇරිස්ටයිඩ්',\n",
       " 'බ්ලොක්',\n",
       " 'දොන්',\n",
       " 'තිලානි',\n",
       " 'සුඩොෆ්',\n",
       " 'කුඩලිගම',\n",
       " 'බිහාරි',\n",
       " 'ධර්මතිලක',\n",
       " 'බ්\\u200dරිතාන්\\u200dයයේ',\n",
       " 'සුගත්',\n",
       " 'ගිහාන්',\n",
       " 'පබසරා',\n",
       " 'ඉෂාර',\n",
       " 'සදාම්',\n",
       " 'දි.',\n",
       " 'ඕවිටිගම',\n",
       " 'රූබි',\n",
       " 'අබේරත්න',\n",
       " 'තාප',\n",
       " 'හිමාෂි',\n",
       " 'සෝමරතන',\n",
       " 'ගංගොඩවිල',\n",
       " 'මංජුලා',\n",
       " 'විජයනාග',\n",
       " 'විනීතා',\n",
       " 'ජුලියන්',\n",
       " 'ධනවංශ',\n",
       " 'යොන්',\n",
       " 'මහීපාල',\n",
       " 'උදාර',\n",
       " 'විට්',\n",
       " 'සාලනී',\n",
       " 'ආම්ස්ට්\\u200dරෝං',\n",
       " 'නිමල්',\n",
       " 'අතල්',\n",
       " 'සාදර්',\n",
       " 'ගොරඩි\\u200dයේ',\n",
       " 'ඔබාමා',\n",
       " 'සේනවිරත්න',\n",
       " 'චම්පා',\n",
       " 'ඔස්ටින්',\n",
       " 'ගඩාෆිට',\n",
       " 'ඩේවිඩ්',\n",
       " 'අබු',\n",
       " '(විමුක්ති',\n",
       " 'තාරක',\n",
       " 'දිඹුල්කුඹුරේ',\n",
       " 'ඇන්ජලෝ',\n",
       " 'නිශ්ශංක',\n",
       " 'ඩුවේලියර්',\n",
       " 'පසිඳු',\n",
       " 'ඩයනා',\n",
       " 'නෙග්රොපොන්ටි',\n",
       " 'සාලික',\n",
       " 'අරෆත්',\n",
       " 'සරත්',\n",
       " 'බර්ට්\\u200dරන්ඩ්',\n",
       " 'ලාල්ජිගේ',\n",
       " 'ලාලනී',\n",
       " 'කිඩ්',\n",
       " 'අලහප්පෙරුම',\n",
       " 'තරංගා',\n",
       " 'රාණි',\n",
       " 'චිරාත්',\n",
       " 'දිනිති',\n",
       " 'චන්ද්\\u200dරරතන',\n",
       " 'සීලවිමල',\n",
       " 'සචිත',\n",
       " 'චාර්ල්ස්',\n",
       " 'ඉසංකාද',\n",
       " 'රොහාන්',\n",
       " 'තාරකා',\n",
       " 'නාරම්මල',\n",
       " 'කුසුම්',\n",
       " 'චන්ද්\\u200dරිකා',\n",
       " 'දෝනි',\n",
       " 'ශානිකා',\n",
       " 'විමල්',\n",
       " 'ගුණසේකර',\n",
       " 'රවිඳුටත්',\n",
       " 'ප\\u200d්\\u200dරනාන්දු',\n",
       " 'අල්',\n",
       " 'දිසානායක',\n",
       " 'වැලෙන්ටිනා',\n",
       " 'චන්න',\n",
       " 'ඊරියගම',\n",
       " 'නසාර්ගෙන්',\n",
       " 'ෂර්මා',\n",
       " 'හොෂියාර්',\n",
       " 'ආතර්',\n",
       " 'රවිඳු',\n",
       " 'තිලක්ෂ',\n",
       " 'දේවානන්ද',\n",
       " 'චමිල',\n",
       " 'කුමාර්',\n",
       " 'කළුබෝවිල',\n",
       " 'හියුගෝ',\n",
       " 'රන්තිසි',\n",
       " 'සරෝජනී',\n",
       " 'උචිත',\n",
       " 'ශක්ති',\n",
       " 'ඇසේන්ජ්',\n",
       " 'කාලෝස්',\n",
       " 'විනීත',\n",
       " 'මල්කි',\n",
       " 'උදය',\n",
       " 'වොන්',\n",
       " 'මධු',\n",
       " 'ලීලාම්බිගෙයි',\n",
       " 'පළමුවැනි',\n",
       " 'චන්ද්\\u200dරබාබු',\n",
       " 'සචින්',\n",
       " 'ජයලත්',\n",
       " 'කුලසිරිබුදවත්ත',\n",
       " 'කුමාරි',\n",
       " 'ග්\\u200dරැහැම්',\n",
       " 'බණ්ඩාරනායක',\n",
       " 'විජිත්',\n",
       " 'සහන්',\n",
       " 'කූෆු',\n",
       " 'කෙනඩිගේ',\n",
       " 'හුසේන්ගෙන්',\n",
       " 'සුනිල්',\n",
       " 'අලි',\n",
       " 'වික්\\u200dරමසිංහ',\n",
       " 'මැතිව්ස්',\n",
       " 'දේශප්\\u200dරිය',\n",
       " 'නිලක්ෂි',\n",
       " 'ප්\\u200dරේමරත්න',\n",
       " 'ජුවාන්',\n",
       " 'සිං',\n",
       " 'කසුන්',\n",
       " 'ශෛලපර්වතාරාමාධිපති',\n",
       " 'හිරිඹුරේගම',\n",
       " 'පමුදි',\n",
       " 'බණ්ඩාරවත්ත',\n",
       " 'කොනී',\n",
       " 'ඕල්ඞී\\u200d්\\u200dරන්',\n",
       " 'සුධම්ම',\n",
       " 'මෙනුෂිකා',\n",
       " 'විජේවර්ධන',\n",
       " 'ඉන්දිරා',\n",
       " 'පෝටරි',\n",
       " 'නසර්',\n",
       " 'ලැන්ටෝස්ගේ',\n",
       " 'හතරවැනි',\n",
       " 'ගුස්ටෝව්',\n",
       " 'ධම්ම',\n",
       " 'අන්නන්ට',\n",
       " 'රාඕ',\n",
       " 'පානේ',\n",
       " 'ජාස්පල්',\n",
       " 'මංජිත්',\n",
       " 'චන්ද්\\u200dරරත්න',\n",
       " 'ලාල්ජි',\n",
       " 'කොබ්බෑකඩුව',\n",
       " 'වික්\\u200dරමගේ',\n",
       " 'අර්ජුන්',\n",
       " 'රූපසිංහ',\n",
       " 'මධුවන්ත',\n",
       " 'පේගන්',\n",
       " 'වජ්පායි',\n",
       " 'සෙල්වරාජා',\n",
       " 'අංජන',\n",
       " 'කරුණා',\n",
       " 'සංගක්කාර',\n",
       " 'ලක්මාලි',\n",
       " 'ජයරත්න',\n",
       " 'පාඨලී',\n",
       " 'බර්ට්රන්ට්',\n",
       " 'මුස්තාපා',\n",
       " 'ලසිදු',\n",
       " 'ප්\\u200dරියදර්ශනී',\n",
       " 'නිහාල්',\n",
       " 'ෆෙල්ඩ්',\n",
       " 'අහමඩ්',\n",
       " 'කුමාරයාගේ',\n",
       " 'සීසන්ද',\n",
       " 'රාහුල්ගේ',\n",
       " 'නිලූක',\n",
       " 'ලෙනාඞ්',\n",
       " 'චම්පික',\n",
       " 'ලාඩන්ගේ',\n",
       " 'නායිදුගේ',\n",
       " 'පහළගම',\n",
       " 'බ\\u200d්\\u200dරැඞ්ලි',\n",
       " 'ධර්මේන්ද්\\u200dර',\n",
       " 'පුලිදේවන්',\n",
       " 'කලවාන',\n",
       " 'ඉසුරිකා',\n",
       " 'ලොවෙල්',\n",
       " 'මඩවල',\n",
       " 'බැද්දේවෙල',\n",
       " 'දුෂන්ති',\n",
       " 'ගිම්හානි',\n",
       " 'එච්.',\n",
       " 'අයි.',\n",
       " 'උෂාන්',\n",
       " 'ගල්කඩුව',\n",
       " 'මැදවල',\n",
       " 'එන්.',\n",
       " 'තරිඳු',\n",
       " 'අද්වානි',\n",
       " 'නානායක්කාරවසම්',\n",
       " 'මාලනී)',\n",
       " 'එරික්',\n",
       " 'කෙවින්',\n",
       " 'ඔගස්ටී',\n",
       " 'සිස්නේරස්',\n",
       " 'මැක්සන්',\n",
       " 'ෆීල්ඩ්',\n",
       " 'මහෙල',\n",
       " 'ලින්ඩ්සේ',\n",
       " 'චෙරේසා',\n",
       " 'රජිව්ගේ',\n",
       " 'එඞ්වර්ඞ්',\n",
       " 'බුදවත්ත',\n",
       " 'චාවේස්',\n",
       " 'අබේසිංහ',\n",
       " 'හපුආරච්චි',\n",
       " 'කුමාරසිරි',\n",
       " 'නොබෙල්ය',\n",
       " 'පියරත්න',\n",
       " 'මීමන',\n",
       " 'සුභාෂණ',\n",
       " 'කෙනඩි',\n",
       " 'ෂයිනි',\n",
       " 'එව්.',\n",
       " 'රොෂානා',\n",
       " 'කුලතුංග',\n",
       " 'රාජා',\n",
       " 'මාලිංග',\n",
       " 'නිස්සංක',\n",
       " 'ඩබ්ලිව්',\n",
       " 'එමිල්',\n",
       " 'මැක්',\n",
       " 'මාදිනී',\n",
       " 'මෝහන්',\n",
       " 'අරුණ',\n",
       " 'එච්',\n",
       " 'කොනින්ග්හැම්',\n",
       " 'සීතා',\n",
       " 'කුෆූගේ',\n",
       " 'රංජිත්',\n",
       " 'කාරියකරවන',\n",
       " 'ගයේෂි',\n",
       " 'බ්\\u200dරිමර්ගේ',\n",
       " 'රේණුකා',\n",
       " 'ද',\n",
       " 'හොරොඩෝටස්',\n",
       " 'අසෝක',\n",
       " 'චාමර',\n",
       " '1',\n",
       " 'හරින්ද්\\u200dරි',\n",
       " 'මිලර්',\n",
       " 'බාලසූරිය',\n",
       " 'ග්ලෙන්',\n",
       " 'ඇලෙක්සි',\n",
       " 'ජීන්',\n",
       " 'ලාලනි',\n",
       " 'අන්නන්',\n",
       " 'අරෝෂා',\n",
       " 'සමරසිංහ',\n",
       " 'ප්\\u200dරසන්නගේ',\n",
       " 'චිත්\\u200dරසේන',\n",
       " 'ඩවුනර්',\n",
       " 'නිලූකට',\n",
       " 'රන්වල',\n",
       " 'බහදුර්',\n",
       " 'ලියොන්',\n",
       " 'ගිලාන්ඩ්',\n",
       " 'ප\\u200d්\\u200dරියංගිකා',\n",
       " 'රෝහණ',\n",
       " 'මහින්දානන්ද',\n",
       " 'රුඞ්',\n",
       " 'අරුන්දතී',\n",
       " 'ගලගෙදර',\n",
       " 'වින්ෆ්\\u200dරීටත්',\n",
       " 'මිණිකිරණි',\n",
       " 'කමලේශ්',\n",
       " 'බ්\\u200dරැන්ඩන්',\n",
       " 'ගැමුණු',\n",
       " 'දිලෝන්',\n",
       " 'ඉන්දිකා',\n",
       " 'ජාතික',\n",
       " 'ටෝනි',\n",
       " 'මාෂාගේ',\n",
       " 'සේනානායක',\n",
       " 'ප්\\u200dරේමලාල්',\n",
       " 'ජෝජ්',\n",
       " 'පැවිට්',\n",
       " 'ධර්ප්\\u200dරිය',\n",
       " 'සායි',\n",
       " 'උඩුකල',\n",
       " 'කුරුගල',\n",
       " 'ඇට්වුඞ්ට',\n",
       " 'ලූණුවිල',\n",
       " 'ෆ්\\u200dරාන්සස්',\n",
       " 'වජිරඤාණ',\n",
       " 'නුවන්',\n",
       " 'ඉරාකීයයන්ට',\n",
       " 'ලක්කාන්ත',\n",
       " 'යූජීන්',\n",
       " 'මු.',\n",
       " 'මුසවේනිගේ',\n",
       " 'විල්ප්\\u200dරඩ්',\n",
       " 'විජේනායක',\n",
       " 'හීත්',\n",
       " 'විශ්ව',\n",
       " 'මැක්සිම්',\n",
       " 'ඩිල්ෂාන්',\n",
       " 'ඉසුරු',\n",
       " 'අවිශ්ක',\n",
       " 'ප්\\u200dරතාබ්',\n",
       " 'සුමිත්',\n",
       " 'රන්සෑගොඩ',\n",
       " 'වීරසිංහ',\n",
       " 'විපුල්',\n",
       " 'එලියතම්බි',\n",
       " 'බ\\u200d්\\u200dරැන්සන්',\n",
       " 'මාර්ටින්',\n",
       " 'ස්ටීවන්',\n",
       " 'ගඩාෆිගේ',\n",
       " 'ලසිත්',\n",
       " 'බවුෂර්',\n",
       " 'මාධව',\n",
       " 'ස්ටැෆර්ඞ්',\n",
       " 'දර්ශනී',\n",
       " 'ෆ\\u200d්\\u200dරෑන්ක්',\n",
       " 'පේජ්',\n",
       " 'සිගැංග්',\n",
       " 'හැගී\\u200d්\\u200dරන්',\n",
       " 'වයිට්',\n",
       " 'අබේසිරි',\n",
       " 'දේවපුර',\n",
       " 'රොත්මන්',\n",
       " 'හැරිස්',\n",
       " 'පියදාස',\n",
       " 'දිලිනි',\n",
       " 'ක්ලෝඩ්',\n",
       " 'ජයනාත්',\n",
       " 'ගාන්ධිලා',\n",
       " 'කොලින්',\n",
       " 'ෂෙල්ටන්',\n",
       " 'සංජය',\n",
       " 'ෆාරුක්',\n",
       " 'යසපාල',\n",
       " 'නීල්',\n",
       " 'කණුගල',\n",
       " 'කමලේෂ්',\n",
       " 'ටෝනී',\n",
       " 'භාසුරු',\n",
       " 'කුමාර',\n",
       " 'වේටර්ස්',\n",
       " 'ඩිලාන්',\n",
       " 'සඳුනි',\n",
       " 'ශිව්රාජ්',\n",
       " 'ටෙනෙට්ටත්',\n",
       " 'කේශාරි',\n",
       " 'වර්ණකුමාර',\n",
       " 'ඉරෝෂන්',\n",
       " 'ලොකු',\n",
       " 'ටිකිරි',\n",
       " 'කෝලිතභානු',\n",
       " 'තිසේරා',\n",
       " 'මොහාන්',\n",
       " 'හිමියන්ගේ',\n",
       " 'ලක්ප්\\u200dරිය',\n",
       " 'ආසාහිමි',\n",
       " 'මාලිනිය',\n",
       " 'මුෂාරෆ්ගේ',\n",
       " 'ජෑන්',\n",
       " 'ඒකනායක',\n",
       " 'වික්\\u200dරමසිංහයන්ගේ',\n",
       " 'මළල්ගොඩ',\n",
       " 'මධුවන්ති',\n",
       " 'ගඩාෆි',\n",
       " 'ඩබ්ලිව්.',\n",
       " 'කුසන්ත',\n",
       " 'වික්\\u200dරමරත්න',\n",
       " 'විද්\\u200dයාපති',\n",
       " 'ජයතිලක',\n",
       " 'කරුණාරත්නගේ',\n",
       " 'අබේකෝන්',\n",
       " 'ජෙරල්ඞ්',\n",
       " 'නෙල්සන්',\n",
       " 'කොස්තා',\n",
       " 'ටයිටන්බෝවා',\n",
       " 'ඕලීෆ්',\n",
       " 'හබරාදුවේ',\n",
       " 'තිස්ස',\n",
       " 'නෝර්මා',\n",
       " 'සුමංගල',\n",
       " 'විජයවර්ධන',\n",
       " 'තමිල්',\n",
       " 'මිලින්ද',\n",
       " 'මෑනිං',\n",
       " 'ෆායිස්',\n",
       " 'ඒරියල්',\n",
       " 'පීරීස්',\n",
       " 'රවින්ද්\\u200dර',\n",
       " 'මනාෂා',\n",
       " 'සමුද්\\u200dරිය',\n",
       " 'නිමේෂා',\n",
       " 'රවීන්',\n",
       " 'මීපගේ',\n",
       " 'සමන්',\n",
       " 'යොවෙර්',\n",
       " 'මෙන්ඩිස්',\n",
       " 'පුස්සදෙණිය',\n",
       " 'මිෂෙල්',\n",
       " 'රොහන්',\n",
       " 'හිඳුරන්ගල',\n",
       " 'තරිඳ',\n",
       " 'ඉන්දික',\n",
       " 'නෙවිල්',\n",
       " 'ෂොකට්',\n",
       " 'එම්',\n",
       " 'ජයසුන්දර',\n",
       " 'මිචෙල්',\n",
       " 'හැන්සන්',\n",
       " 'මැකේන්ද',\n",
       " 'අකලංක',\n",
       " 'නන්දසේන',\n",
       " 'තේජාන්',\n",
       " 'පීරිස්',\n",
       " 'දීයකඩුවේ',\n",
       " 'ඇලන්',\n",
       " 'ෆැමා',\n",
       " 'අබේගුණසේකර',\n",
       " 'ඇරිස්ටයිඩ්ට',\n",
       " 'මේ',\n",
       " 'එඞ්වඞ්',\n",
       " 'ගි\\u200d්\\u200dරසම්',\n",
       " 'එල්.',\n",
       " 'හුසේන්',\n",
       " 'ගාන්ධිලාගෙන්',\n",
       " 'ලියනගමගේ',\n",
       " 'වික\\u200d්\\u200dරමසිංහ',\n",
       " 'හෂාන්',\n",
       " 'රණවීර',\n",
       " 'ධර්මප්\\u200dරිය',\n",
       " 'සඳජානි',\n",
       " 'කාංචන',\n",
       " 'සේනාරත්න',\n",
       " 'ඩෙනිස්',\n",
       " 'හෝම්ස්',\n",
       " 'කොමරෝෆ්',\n",
       " 'පියනෝෆ්',\n",
       " 'ස්පෙන්සර්',\n",
       " 'ආරොන්',\n",
       " 'ගම්මන්පිල',\n",
       " 'ෂැලෝන්',\n",
       " 'ඇන්ඩර්ස්',\n",
       " 'රූබසිංහ',\n",
       " 'පිනිදියආරච්චි',\n",
       " 'ප්\\u200dරසාද්',\n",
       " '(කනිෂ්ඨ)',\n",
       " 'ජයසේකර',\n",
       " 'නාලක',\n",
       " 'වෙදගෙදර',\n",
       " 'තිසුරුලාවන්\\u200dය',\n",
       " 'ඇලිස්',\n",
       " 'ලියනගේ',\n",
       " 'චාමින්',\n",
       " 'කූෆූ',\n",
       " 'කැස්ත්\\u200dරෝගේ',\n",
       " 'ඔසාමා',\n",
       " 'බර්ට්රන්ඩ්',\n",
       " 'මුෂාරෆ්ට',\n",
       " 'මිත්\\u200dරරත්න',\n",
       " 'එරියල්',\n",
       " 'බොඑහ්නර්',\n",
       " 'දයානන්ද',\n",
       " 'මාබුව්',\n",
       " 'රිචඩ්',\n",
       " 'දයාරත්න',\n",
       " 'ෂීන්',\n",
       " 'ටොම්',\n",
       " 'සෝනියා',\n",
       " 'පර්වේස්',\n",
       " 'හැම්',\n",
       " 'වී.',\n",
       " 'නවරත්න',\n",
       " 'ලැරී',\n",
       " 'ගගාරීන්ගේ',\n",
       " 'පැරකුම්බා',\n",
       " 'පියල්',\n",
       " 'අම්මාන්ගේ',\n",
       " 'එඞ්වින්',\n",
       " 'රොෂෙල්',\n",
       " 'මුන්රෝය',\n",
       " 'මාගම්මන',\n",
       " 'සුමනසිරි',\n",
       " 'සුපිපි',\n",
       " 'තනුජ',\n",
       " 'මාෂා”',\n",
       " 'නිමේෂිකා',\n",
       " 'සිරිවර්ධන',\n",
       " 'ලාල්',\n",
       " 'ලාඩන්ගෙන්',\n",
       " 'ප්\\u200dරභාකරන්',\n",
       " 'චන්ද්\\u200dරපේ\\u200d්\\u200dරම',\n",
       " 'උපශාන්ත',\n",
       " 'වෛරමුත්තු',\n",
       " 'ටිටෝ',\n",
       " 'ධනපාල',\n",
       " 'වි.',\n",
       " 'කාංචනා',\n",
       " 'සයවැනි',\n",
       " 'දිනේෂ්',\n",
       " 'මිත්\\u200dරරත්නගේ',\n",
       " 'රොයුසෙෆ්',\n",
       " 'රත්නායක',\n",
       " 'බෝමන්',\n",
       " 'බිබිලේ',\n",
       " 'ජයලාල්',\n",
       " 'තිළණි',\n",
       " 'ලියන්',\n",
       " 'දිල්රුක්ෂි',\n",
       " 'කේ',\n",
       " 'මාස්ටර්',\n",
       " 'ගාන්ධිගෙන්',\n",
       " 'ජයලලිතාගේ',\n",
       " 'අබේවික්\\u200dරම',\n",
       " 'කාලොස්',\n",
       " 'ජෝන්',\n",
       " 'අශාන්',\n",
       " 'ගිලාඞ්',\n",
       " 'යසින්',\n",
       " 'ජයවර්ධන',\n",
       " 'ගරුසිංහ',\n",
       " 'හෑන්ඩ්',\n",
       " 'මුදියන්සේ',\n",
       " 'ගුණර්ධන',\n",
       " 'ඇලන්ටීන්',\n",
       " 'ෂෙහාරි',\n",
       " 'නරසිම්හ',\n",
       " 'නිසල්',\n",
       " 'පෑන්ස්',\n",
       " 'කනිංහැම්',\n",
       " 'සවණබැද්ද',\n",
       " 'තිලකරත්න',\n",
       " 'බන්ධුල\\xa0',\n",
       " 'ප්\\u200dරියන්ත',\n",
       " 'සාසෙයිනි',\n",
       " 'පරණවිතාන',\n",
       " 'රනිල්',\n",
       " 'මාලතී',\n",
       " 'සැන්කුරේ',\n",
       " 'රණසිංහ',\n",
       " 'රාහුල්',\n",
       " 'ආලෝක',\n",
       " 'සිල්වෙස්ටර්',\n",
       " 'රොබින්',\n",
       " 'එමිලා',\n",
       " 'ෂින්ගේ',\n",
       " 'සෙල්වන්',\n",
       " 'යූ.',\n",
       " 'යූරි',\n",
       " 'ඇරිස්ටයිඩ්ගේ',\n",
       " 'මොආමර්',\n",
       " 'ෂින්',\n",
       " 'ඔබාමාගේ',\n",
       " 'චම්පිකා',\n",
       " 'කොයිසුම්',\n",
       " 'විහඟ',\n",
       " 'වේළුපිල්ලේ',\n",
       " 'අව්රල්',\n",
       " 'කල්තොට',\n",
       " 'කොඩිතුවක්කු',\n",
       " 'කාලෝ',\n",
       " 'නිර්මාල්',\n",
       " 'ජයාංගි',\n",
       " 'ලියනෝෆ්',\n",
       " 'සමරනායක',\n",
       " 'සත්\\u200dයසීලන්',\n",
       " 'බුෂ්ට',\n",
       " 'සාදර්ගේ',\n",
       " 'හේමපාල',\n",
       " 'දිනෝද්',\n",
       " 'සෙහාන්',\n",
       " 'කුෂාන්',\n",
       " 'සිල්වියෝ',\n",
       " 'ආශා',\n",
       " 'පාලිත',\n",
       " 'කේ.',\n",
       " 'අර්ඞ්මන්ට',\n",
       " 'ලුවී',\n",
       " 'මැස්කෝයි',\n",
       " 'ගුණරත්න',\n",
       " 'නතාෂා',\n",
       " 'ටැන්ඩන්',\n",
       " 'තිනියාවල',\n",
       " 'අහ්මද්',\n",
       " 'ෂෙපර්ඞ්ගේ',\n",
       " 'ජගත්',\n",
       " 'පෑතිස්',\n",
       " 'අල්ගම',\n",
       " 'ගම්හානිගේ',\n",
       " 'ගඩාෆිගෙන්',\n",
       " 'වික්\\u200dරමආරච්චි',\n",
       " 'ෆලූජා',\n",
       " 'අබ්දුල්',\n",
       " 'සාගර',\n",
       " 'රන්දීව්ට',\n",
       " 'සිල්වියා',\n",
       " 'ආනන්ද',\n",
       " 'චේතික',\n",
       " 'නිෂාන්',\n",
       " 'සෝමවංශ',\n",
       " 'මහින්ද',\n",
       " 'රත්නායකට',\n",
       " 'ඉම්හොටෙප්',\n",
       " 'චන්ද්\\u200dරානි',\n",
       " 'ඞී.',\n",
       " 'පුෂ්පකුමාර',\n",
       " 'ජොර්ජ්',\n",
       " 'අසිස්',\n",
       " 'සිතාරාම්',\n",
       " 'අබේවික\\u200d්\\u200dරම',\n",
       " '‘‘බන්ටි',\n",
       " 'මුකර්ජි',\n",
       " 'අබ්දුල්ෂාඩ්',\n",
       " 'දුමින්ද',\n",
       " 'ශිරාණි',\n",
       " 'සෙනරත්',\n",
       " 'ස්ටෙෆෝනි',\n",
       " 'චාන්ට',\n",
       " 'කුඹුර',\n",
       " 'රයිස්',\n",
       " 'සුලෝචනී',\n",
       " 'බ්ලෙයාර්ට',\n",
       " 'රන්දීව්',\n",
       " 'අප්පුහාමි',\n",
       " 'ජයවික\\u200d්\\u200dරම',\n",
       " 'ගෝර්කිගේ',\n",
       " 'ඩවුනර්ගේත්',\n",
       " 'බඹසර',\n",
       " 'පේෂල',\n",
       " 'කොයිරාළ',\n",
       " 'ඔප්රා',\n",
       " 'ඩිල්මා',\n",
       " 'ඇස්කි',\n",
       " 'සුරාජ්',\n",
       " 'චන්ද්\\u200dරෂාන්',\n",
       " 'රාජපක්\\u200dෂ',\n",
       " 'විජේවීර',\n",
       " 'රෝයි',\n",
       " 'ලක්දාර්',\n",
       " 'උදයකාන්ත',\n",
       " 'මිලින්දව',\n",
       " 'ධර්ම',\n",
       " 'සුමේධවංශ',\n",
       " 'වර්ජිල්',\n",
       " 'වානගුරු',\n",
       " 'අබේවීර',\n",
       " 'රත්නසිරි',\n",
       " 'කෝට්නි',\n",
       " 'පත්මසීලි',\n",
       " 'එෆ්.',\n",
       " 'ටි.',\n",
       " 'අර්නාස්',\n",
       " 'ෂර්ලොක්',\n",
       " 'ඩයනාගේ',\n",
       " 'මුසාබ්',\n",
       " 'ඉනෝකා',\n",
       " 'හේවාවිතාරණ',\n",
       " 'නයනානන්ද',\n",
       " 'රුපියල්',\n",
       " 'සැන්කුරේගේ',\n",
       " 'සම්පත්',\n",
       " 'හැරී',\n",
       " 'අභයබණ්ඩාර',\n",
       " 'ජයසිංහ',\n",
       " 'ෆ්\\u200dරන්සුවා',\n",
       " 'එළිසාගේ',\n",
       " 'විජේසිංහ',\n",
       " 'නන්දනතිලක',\n",
       " 'ලූසිත',\n",
       " 'දිල්ශාන්',\n",
       " 'භිමල්',\n",
       " 'ජොන්සන්ට',\n",
       " 'පරාක්\\u200dරම',\n",
       " 'ඛාන්',\n",
       " 'එඩ්වඩ්',\n",
       " 'ශිරානි',\n",
       " 'ඉස්ලාම්',\n",
       " 'රබ්බිඩිගල',\n",
       " 'කුමාරිහාමි',\n",
       " 'ඊ.',\n",
       " 'සරණසිරි',\n",
       " 'දීපිකා',\n",
       " 'මන්මෝහන්',\n",
       " 'මධුශංක',\n",
       " 'ජයසූරිය',\n",
       " 'මල්ලිකා',\n",
       " 'ඉෂාක්',\n",
       " 'සංගරී',\n",
       " 'මුආමර්',\n",
       " 'මහදුර',\n",
       " 'ගුණතිලක',\n",
       " 'ජී.',\n",
       " 'පීටර්',\n",
       " 'කුමරුගේ',\n",
       " 'පහෙස්',\n",
       " 'මෆ්ටි',\n",
       " 'දුලාජ්',\n",
       " 'වැනි',\n",
       " 'සයුගනෝව්ට',\n",
       " 'වික්\\u200dරමසිංහයන්',\n",
       " 'අයතොල්ලා',\n",
       " 'තෙරස්කෝවා',\n",
       " 'පෝල්',\n",
       " 'රන්දීව්ගේ',\n",
       " 'ලියු',\n",
       " 'ආදම්ගේ',\n",
       " 'කූෆුගේ',\n",
       " 'හෙට්ටිආරච්චි',\n",
       " 'හියුන්ට',\n",
       " 'ප්\\u200dරේමජයනත්',\n",
       " 'නිශාදි',\n",
       " 'එන්ග්ලේය',\n",
       " 'යසර්',\n",
       " 'බ්ලෙයාර්ගේ',\n",
       " 'බිම්සර',\n",
       " 'සුරවීර',\n",
       " 'ඒ.',\n",
       " 'බෙර්ලුස්කොනි',\n",
       " 'පි.',\n",
       " 'රාජකරුණා',\n",
       " 'ෂැෆේ',\n",
       " 'ජෝශප්',\n",
       " 'කෙනඩිට',\n",
       " 'පණ්ඩුල',\n",
       " 'හේමා',\n",
       " 'මාලක',\n",
       " 'සුනිලා',\n",
       " 'විද්\\u200dයාරත්න',\n",
       " 'චන්ද්\\u200dරසිරි',\n",
       " 'අශෝක',\n",
       " 'ෂාන්ඩ්',\n",
       " 'අලුත්ගමගේ',\n",
       " 'ජෙනිෆර්',\n",
       " 'මර්ජෝරී',\n",
       " 'රීස්',\n",
       " 'ගාන්ධිගේ',\n",
       " 'රවිබන්දු',\n",
       " 'රොජර්',\n",
       " 'ශොහාන්',\n",
       " 'කැමරන්',\n",
       " 'විජේසූරිය',\n",
       " 'ෂාම්',\n",
       " 'ශිරෝන්',\n",
       " 'විග්නේෂ්වරන්',\n",
       " 'උඩුපීල්ල',\n",
       " 'නයිඳු',\n",
       " 'වර්නර්',\n",
       " 'මැන්දිස්',\n",
       " 'ජනක',\n",
       " 'අතාල්',\n",
       " 'ක්\\u200dරීස්',\n",
       " 'සුරංග',\n",
       " 'රන්දිමාල්',\n",
       " 'සුපෙම්',\n",
       " 'මොහොට්ටි',\n",
       " 'රිචඞ්',\n",
       " 'කවීන්',\n",
       " 'මලේක්',\n",
       " 'ඉසදීන්',\n",
       " 'අවාටා',\n",
       " 'නිර්මලා',\n",
       " 'අසනුල්ලා',\n",
       " 'කොට්රෝචි',\n",
       " 'මන්',\n",
       " 'බෙග්',\n",
       " 'පරගස්තොට',\n",
       " 'ලුයී',\n",
       " 'බ්ලෙයාර්',\n",
       " 'ඛේමා',\n",
       " 'පිදෙල්',\n",
       " 'අනුර',\n",
       " 'ප්\\u200dරමිතා',\n",
       " 'මේරි',\n",
       " 'මලාලා',\n",
       " 'සැපටේරෝ',\n",
       " 'එස්.',\n",
       " 'මහත්මා',\n",
       " 'විජයලක්ෂ්මී',\n",
       " 'ජොනතන්',\n",
       " 'රොබට්',\n",
       " 'කවිඳු',\n",
       " 'බ්\\u200dරහිමි',\n",
       " 'කාරියවසම්',\n",
       " 'වජ්පායිට',\n",
       " 'වර්නන්',\n",
       " 'කොන්ඩලීසා',\n",
       " 'අජන්තා',\n",
       " 'කෙරී',\n",
       " 'රණතුංග',\n",
       " 'මර්ලින්',\n",
       " 'හර්ෂ',\n",
       " 'අර්ඞ්මන්',\n",
       " 'යූසොෆ්සායි',\n",
       " 'බුෂ්ගේ',\n",
       " 'චන්ද්\\u200dරසේකර',\n",
       " 'රීඩ්',\n",
       " 'කලිදු',\n",
       " 'ප්\\u200dරනාන්දු',\n",
       " 'ප්\\u200dරංශුවා',\n",
       " 'අළුවිහාරේ',\n",
       " 'ගමගේ',\n",
       " 'යාසින්',\n",
       " 'රදැල්ල',\n",
       " 'කාර්පුස්',\n",
       " 'සචින්ත්\\u200dයා',\n",
       " 'රදිකා',\n",
       " 'සල්වාන්',\n",
       " 'අනුරුද්ධිකා',\n",
       " 'ෂෙමිඩ්ට්',\n",
       " 'ප්\\u200dරේමජයන්ත',\n",
       " 'රාජපක්ෂ',\n",
       " 'පරාක\\u200d්\\u200dරම',\n",
       " 'බවුන්',\n",
       " 'කලාම්',\n",
       " 'දමිතා',\n",
       " 'චාල්ස්',\n",
       " 'අබ්දල්',\n",
       " 'ගෝඨාභය',\n",
       " 'විජය',\n",
       " 'සුසිල්',\n",
       " 'අතුල',\n",
       " 'තෝමස්',\n",
       " 'හේරත්',\n",
       " 'සෙනෙවිරත්න',\n",
       " 'ගාන්ධි',\n",
       " 'සැන්ග්',\n",
       " 'තක්ෂලි',\n",
       " 'ඕබ්රි',\n",
       " 'චන්දිමාල්',\n",
       " 'සෞම්\\u200dයා',\n",
       " 'දස්කොන්',\n",
       " 'අමුණුගම',\n",
       " 'උපේකා',\n",
       " 'රන්දික',\n",
       " 'ගුණවර්ධන',\n",
       " 'ෂීක්',\n",
       " 'මැකෙන්',\n",
       " 'ජීවන්ත',\n",
       " 'ආණ්ඩුව',\n",
       " 'කන්නන්ගර',\n",
       " 'ධර්මසේන',\n",
       " 'මාලේන්',\n",
       " 'සින්ඩේ',\n",
       " 'නදී',\n",
       " 'හේමමාලි',\n",
       " 'අනන්ද',\n",
       " 'මහාමායා',\n",
       " 'කරුණාතිලක',\n",
       " 'යාසීන්',\n",
       " 'මංගල',\n",
       " 'චම්මි',\n",
       " 'සමරතුංග',\n",
       " 'ශ්\\u200dරී',\n",
       " 'ඔලිවර්',\n",
       " 'සිරිසේනආරච්චි',\n",
       " 'අ\\u200dබේ\\u200dසේකර',\n",
       " 'බන්දුල',\n",
       " 'මයිකල්',\n",
       " 'චන්ද්\\u200dරාබාබු',\n",
       " 'එම්බකි',\n",
       " 'සී.',\n",
       " '‘‘සයුමිට',\n",
       " 'කුලවංශ',\n",
       " 'සැරියුත්',\n",
       " 'රංජන්',\n",
       " 'චන්දන',\n",
       " 'ස්මිත්ටයි',\n",
       " 'ආර්',\n",
       " 'ඔල්ටිමිරානෝ',\n",
       " 'අමිතා',\n",
       " 'මුන්රෝව',\n",
       " 'පියරතන',\n",
       " 'රම්ස්',\n",
       " 'ශ්\\u200dරීයානි',\n",
       " 'රංගනාත්',\n",
       " 'සමන්ත',\n",
       " 'ලෝපෙස්',\n",
       " 'ගයනේන්ද්\\u200dර',\n",
       " 'ඩලස්',\n",
       " 'දුලීකා',\n",
       " 'හොරණ',\n",
       " 'සිදුහත්',\n",
       " 'ගෙනඩි',\n",
       " 'නිවුන්හැල්ලේ',\n",
       " 'තිසල්ගේ',\n",
       " 'කුලසිරි',\n",
       " 'පී.',\n",
       " 'රණවක',\n",
       " 'පක්\\u200dඳ්ක්\\u200dඳාසේකර',\n",
       " 'මොරගොඩ',\n",
       " 'හර්ෂා',\n",
       " 'මේතා',\n",
       " 'ජෝස්',\n",
       " 'රොඩ්රිගෝස්',\n",
       " 'බී.',\n",
       " 'හෝකින්ස්',\n",
       " 'සුලෝචන',\n",
       " 'තහා',\n",
       " 'කනිං',\n",
       " 'හියුබට්',\n",
       " 'මුනිදාස',\n",
       " 'වසන්ත',\n",
       " 'පක්\\u200dඳ්ක්\\u200dඳානන්ද',\n",
       " 'සෙනුලි',\n",
       " 'රංසිකා',\n",
       " 'හර්ෂන',\n",
       " 'ධම්මිස්සර',\n",
       " 'මායාදුන්න',\n",
       " 'බිමන්ත',\n",
       " 'කුලරත්න',\n",
       " 'සෙනවිරත්න',\n",
       " 'වේරගොඩ',\n",
       " 'ප්\\u200dරියංකා',\n",
       " 'කිමිට්',\n",
       " ...]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(list(set(tags['PER'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4928\n"
     ]
    }
   ],
   "source": [
    "senLst=lines1+lines2\n",
    "senLst='\\n'.join(map(str, senLst))\n",
    "senLst=senLst.split('. O\\n')\n",
    "print(len(senLst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4928\n",
      "4865\n"
     ]
    }
   ],
   "source": [
    "taggedCorpus=[dict(\n",
    "                    [w.split(' ') for w in i.split('\\n') if len(w.split(' '))==2]\n",
    "                  ) \n",
    "              for i in senLst]\n",
    "\n",
    "taggedCorpus=[{\n",
    "                'sen':list(d.keys()),'tags':list(d.values())\n",
    "               } \n",
    "              for d in taggedCorpus]\n",
    "print(len(taggedCorpus))\n",
    "\n",
    "for i,d in enumerate(taggedCorpus):\n",
    "    if len(d['sen'])<3:\n",
    "        del taggedCorpus[i]\n",
    "print(len(taggedCorpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "taggedCorpusTrain=taggedCorpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "print(windowSize) #A centred window of size N around the word to be disambiguated is considered in feature generation. ex 3,5,7,9\n",
    "#make sure minimum sen length is =>windowSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3db6c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "f2 = open(\"D:\\\\#Data_science\\\\Resesrch\\\\Sinhala grammerly research\\\\python\\\\0 resources\\\\suffixes.txt\",encoding='utf-8').read()\n",
    "suffixes=f2.split('\\n')\n",
    "\n",
    "f3 = open(\"D:\\\\#Data_science\\\\Resesrch\\\\Sinhala grammerly research\\\\python\\\\0 resources\\\\eng prepositions.txt\").read()\n",
    "engPrepositions=f3.split('\\n')\n",
    "engPrepositions=[i.lower() for i in engPrepositions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b80b9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "NERFeatures1=['මහතා', 'මහත්මා', 'මහත්මයා','මයා', 'මිය', 'මහත්මිය', 'මෙනවිය', 'හිමි']\n",
    "NERFeatures2=['තුමා','තුමිය','හිමි']\n",
    "toFilter=['ඒ', 'බී', 'සී', 'ඩී','ඩී', 'ඊ' ,'එෆ්', 'ජී' ,'එච්', 'අයි', 'ජේ' ,'කේ', 'එල්', 'එම්', 'ඇම්', 'එන්', 'ඕ' ,'පී', 'කිව්','කියු', 'ආර්', 'එස්' ,'ඇස්','ටී', 'යූ', 'වී', 'ඩබ්ලිව්','ඩබ්ලියු', 'වයි','ඉසෙඩ්','එක්ස්']#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "677c0d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def siToEn(text):\n",
    "  inputs = [text]\n",
    "  outputs = service.translations().list(source='si', target='en', q=inputs).execute()\n",
    "  translated_text = outputs['translations'][0]['translatedText']\n",
    "  translated_text=preProcessTranslation(translated_text)\n",
    "\n",
    "  return translated_text\n",
    "  \n",
    "def isEnglish(enTranslation):\n",
    "    enTranslation=enTranslation.strip()\n",
    "    words=[]\n",
    "    if ' ' in enTranslation:\n",
    "        words=enTranslation.split(' ')\n",
    "    else:\n",
    "        words=[enTranslation]\n",
    " \n",
    "    isEn='1'\n",
    "    for w in words:\n",
    "        if not wordnet.synsets(w):\n",
    "            if w not in engPrepositions:\n",
    "                isEn='0'\n",
    "    return isEn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9358f784",
   "metadata": {},
   "outputs": [],
   "source": [
    "pklFile1=open('siToEn translated totWords dictionary','rb')\n",
    "totWordsTrans=pickle.load(pklFile1)\n",
    "pklFile1.close()\n",
    "\n",
    "pklFile2=open('isEnglish dictionary','rb')\n",
    "totWordsIsEn=pickle.load(pklFile2)\n",
    "pklFile2.close()\n",
    "\n",
    "# totWordsIsEn=defaultdict()\n",
    "# totWordsTrans=defaultdict()\n",
    "# c=3800\n",
    "# for i in lines1+lines:\n",
    "#     tmp=i.split(' ')\n",
    "#     if tmp[0] not in totWordsTrans.keys():\n",
    "#         trans=siToEn(tmp[0])\n",
    "#         totWordsTrans[tmp[0]]=trans\n",
    "#         totWordsIsEn[tmp[0]]=isEnglish(trans)\n",
    "        \n",
    "#         c+=1\n",
    "#         if c%100==0:print(c)\n",
    "\n",
    "# len(totWordsIsEn)\n",
    "\n",
    "\n",
    "## pklFile1=open('siToEn translated totWords dictionary','wb')\n",
    "## pickle.dump(totWordsTrans,pklFile1)\n",
    "## pklFile1.close()\n",
    "\n",
    "## pklFile2=open('isEnglish dictionary','wb')\n",
    "## pickle.dump(totWordsIsEn,pklFile2)\n",
    "## pklFile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd2479f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# totWordsIsEn=defaultdict()\n",
    "# for k,v in totWordsTrans.items():\n",
    "#     totWordsIsEn[k]=isEnglish(v)\n",
    "\n",
    "# len(totWordsIsEn)\n",
    "\n",
    "## pklFile2=open('isEnglish dictionary','wb')\n",
    "## pickle.dump(totWordsIsEn,pklFile2)\n",
    "## pklFile2.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getWindow(sen,ind):\n",
    "    preW,postW='',''\n",
    "\n",
    "    if ind==0:\n",
    "        postW=sen[ind+1]\n",
    "    elif ind==(len(sen)-1):\n",
    "        preW=sen[ind-1]\n",
    "    else:\n",
    "        preW=sen[ind-1]\n",
    "        postW=sen[ind+1]\n",
    "    \n",
    "    return (preW,postW)  \n",
    "\n",
    "\n",
    "\n",
    "def preProcessTranslation(text):\n",
    "  text = text.lower()\n",
    "  text = re.sub(\"[^a-z ]+\", \"\",text)\n",
    "\n",
    "  return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFeatures(tagged_Corpus):\n",
    "    corpusFeatures=defaultdict(list) #columns of final df\n",
    "\n",
    "    for i in tagged_Corpus:\n",
    "        if len(i['sen'])>=3:      \n",
    "            for ind,(w,t) in enumerate(zip(i['sen'],i['tags'])):\n",
    "                corpusFeatures['word'].append(w)\n",
    "                # corpusFeatures['word2'].append(w[-2:])\n",
    "                # corpusFeatures['word3'].append(w[-3:])\n",
    "                corpusFeatures['word3'].append(w[-4:])\n",
    "\n",
    "                digitOrPunct=0\n",
    "                for char in w:\n",
    "                    if char.isdigit() or char in punctuation:\n",
    "                        digitOrPunct=1\n",
    "                corpusFeatures['digitOrPunct'].append(digitOrPunct)\n",
    "\n",
    "                get_window=getWindow((i['sen']),ind)\n",
    "                preWord=get_window[0]\n",
    "                postWord=get_window[1]\n",
    "                corpusFeatures['preWord'].append(preWord)\n",
    "                corpusFeatures['postWord'].append(postWord)\n",
    "                \n",
    "                enLet='0'\n",
    "                if w in toFilter:\n",
    "                    enLet='1'\n",
    "                corpusFeatures['engInitials'].append(enLet)\n",
    "\n",
    "                NER_feature='0'\n",
    "                for nerf in NERFeatures1:\n",
    "                    if postWord.startswith(nerf):\n",
    "                        NER_feature='1'\n",
    "                if NER_feature=='0':\n",
    "                    for nerf in NERFeatures2:\n",
    "                        if postWord.endswith(nerf):\n",
    "                            NER_feature='1'\n",
    "                corpusFeatures['NERFeatures'].append(NER_feature)\n",
    "\n",
    "                isEnflg='1'\n",
    "                if w in totWordsIsEn.keys():\n",
    "                     if totWordsIsEn[w]=='0':\n",
    "                        isEnflg='0'\n",
    "                corpusFeatures['Translation'].append(isEnflg)\n",
    "\n",
    "                possibleSufs=[suf for suf in suffixes if w.endswith(suf)]\n",
    "                possibleSufs.sort(key=len, reverse=True)\n",
    "                if possibleSufs:\n",
    "                    corpusFeatures['suffixes'].append(possibleSufs[0])\n",
    "                else:\n",
    "                    corpusFeatures['suffixes'].append('None') \n",
    "                                \n",
    "                corpusFeatures['wordLen'].append((len(w)))\n",
    "                corpusFeatures['targetTag'].append(t)\n",
    "\n",
    "    featureSetDf=createFeatureSetDf(corpusFeatures) \n",
    "\n",
    "    return featureSetDf\n",
    "\n",
    "def createFeatureSetDf(corpusFeatures):\n",
    "    featureSetDf=pd.DataFrame.from_dict(corpusFeatures,orient='index')\n",
    "    featureSetDf=featureSetDf.transpose()\n",
    "    #print(featureSetDf.head())\n",
    "\n",
    "    return featureSetDf\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generateFeatures(mtaggedCorpusTrain[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainFeatureSetDf=generateFeatures(taggedCorpusTrain)\n",
    "trainFeatureSetDf=trainFeatureSetDf.fillna('0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11109230",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "xDF=trainFeatureSetDf.loc[:,trainFeatureSetDf.columns[0]:trainFeatureSetDf.columns[-2]]\n",
    "ohe=OneHotEncoder(handle_unknown='ignore')\n",
    "x=ohe.fit_transform(xDF)\n",
    "\n",
    "y=trainFeatureSetDf['targetTag'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3fed5cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pklFile4=open('OneHotEncoder.pkl','wb')\n",
    "# pickle.dump(ohe,pklFile4)\n",
    "# pklFile4.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b957fe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90116, 67851)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x and y test sets from same trainFeatureSetDf\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.4,  random_state = 0)#stratify=y,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54069, 67851)\n",
      "(54069,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "001df1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "essentialTags=['PER', 'LOC', 'ORG']#'VFM', 'PRP', \n",
    "def getTagAcc(Classifier,x_test, y_test):\n",
    "    print('Overall : ',Classifier.score(x_test, y_test))\n",
    "    print('total tag score: ',(f1_score(y_test,Classifier.predict(x_test), average=\"weighted\",labels=essentialTags)))#VFM NNC NNP PRP\n",
    "    for i in essentialTags:\n",
    "        print(i,(f1_score(y_test,Classifier.predict(x_test), average=\"weighted\",labels=[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall :  0.909895414320193\n",
      "total tag score:  0.6612243310236311\n",
      "PER 0.7634896621280889\n",
      "LOC 0.6840731070496082\n",
      "ORG 0.5393562347849609\n"
     ]
    }
   ],
   "source": [
    "CNB = ComplementNB()\n",
    "CNB.fit(x_train, y_train)\n",
    "getTagAcc(CNB,x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e11bb600",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pradeep Jayasuriya\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall :  0.938580186978112\n",
      "total tag score:  0.7155567036433885\n",
      "PER 0.8063897763578276\n",
      "LOC 0.7110356536502547\n",
      "ORG 0.6309320587231135\n"
     ]
    }
   ],
   "source": [
    "LR = LogisticRegression()\n",
    "LR.fit(x_train, y_train) \n",
    "getTagAcc(LR,x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fbcb1ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pklFile3=open('NERClassifier','wb')\n",
    "# pickle.dump(LR,pklFile3)\n",
    "# pklFile3.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy_score(y_test,CNB.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_score(y_test,CNB.predict(x_test), average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "id": "962f926a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall :  0.9202152745027325\n",
      "total tag score:  0.6051920348432196\n",
      "PER 0.717491984324902\n",
      "LOC 0.6159667045024594\n",
      "ORG 0.4849921011058451\n"
     ]
    }
   ],
   "source": [
    "SVM = SVC()#SVC, LinearSVC,NuSVC\n",
    "SVM.fit(x_train, y_train)\n",
    "getTagAcc(SVM,x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "265e8294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall :  0.8565761367104059\n",
      "total tag score:  0.0\n",
      "PER 0.0\n",
      "LOC 0.0\n",
      "ORG 0.0\n"
     ]
    }
   ],
   "source": [
    "BNB = BernoulliNB()\n",
    "BNB.fit(x_train, y_train)\n",
    "getTagAcc(BNB,x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "2c8b9f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall :  0.9001303853302632\n",
      "total tag score:  0.4398624559288191\n",
      "PER 0.6616878267363704\n",
      "LOC 0.414374445430346\n",
      "ORG 0.24694973157637876\n"
     ]
    }
   ],
   "source": [
    "MNB = MultinomialNB()\n",
    "MNB.fit(x_train, y_train)\n",
    "getTagAcc(MNB,x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4ad2532e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall :  0.9322828529419924\n",
      "total tag score:  0.6966952401263217\n",
      "PER 0.7819181429444104\n",
      "LOC 0.7065868263473053\n",
      "ORG 0.6038449416955562\n"
     ]
    }
   ],
   "source": [
    "DT = DecisionTreeClassifier()\n",
    "DT.fit(x_train, y_train)\n",
    "getTagAcc(DT,x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall :  0.9326434932171886\n",
      "total tag score:  0.6859144874927589\n",
      "PER 0.7794019933554818\n",
      "LOC 0.6901359358661555\n",
      "ORG 0.5903698534542917\n"
     ]
    }
   ],
   "source": [
    "RF = RandomForestClassifier()\n",
    "RF.fit(x_train, y_train)\n",
    "getTagAcc(RF,x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall :  0.9156379171637029\n",
      "total tag score:  0.6142612358018549\n",
      "PER 0.6906721536351166\n",
      "LOC 0.6435768261964736\n",
      "ORG 0.5115500502176097\n"
     ]
    }
   ],
   "source": [
    "KN = KNeighborsClassifier()\n",
    "KN.fit(x_train, y_train)\n",
    "getTagAcc(KN,x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall :  0.8782422947818126\n",
      "total tag score:  0.28016428092136536\n",
      "PER 0.3517305893358279\n",
      "LOC 0.33423423423423426\n",
      "ORG 0.15863453815261047\n"
     ]
    }
   ],
   "source": [
    "ADB = AdaBoostClassifier()\n",
    "ADB.fit(x_train, y_train)\n",
    "getTagAcc(ADB,x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall :  0.8852886509279552\n",
      "total tag score:  0.32934741005944224\n",
      "PER 0.40969364426154553\n",
      "LOC 0.4091308165057067\n",
      "ORG 0.1747474747474748\n"
     ]
    }
   ],
   "source": [
    "GDB = GradientBoostingClassifier()\n",
    "GDB.fit(x_train, y_train)\n",
    "getTagAcc(GDB,x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(GDB.predict(x_test),y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAM = LogisticGAM()\n",
    "# GAM.fit(X_train, y_train)\n",
    "# GAM.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators=[\n",
    "    #('GDB', GradientBoostingClassifier())\n",
    "    #,('ADB' , AdaBoostClassifier())\n",
    "    #,('SVM' , SVC())\n",
    "    ('RF' , RandomForestClassifier())\n",
    "    ,('LR' , LogisticRegression())\n",
    "    #,('MNB' , MultinomialNB())\n",
    "    #,('GNB' , GaussianNB())\n",
    "    ,('CNB' , ComplementNB())\n",
    "    ,('DT' , DecisionTreeClassifier())\n",
    "    #,('KN' , KNeighborsClassifier()) \n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_estimator=LogisticRegression()\n",
    "\n",
    "# final_estimator = GradientBoostingRegressor(\n",
    "#     n_estimators=25, subsample=0.5, min_samples_leaf=25, max_features=1,\n",
    "#     random_state=42)\n",
    "\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=estimators,\n",
    "    final_estimator=final_estimator)\n",
    "\n",
    "stacked_model.fit(x_train, y_train)\n",
    "getTagAcc(stacked_model,x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d6fabba",
   "metadata": {},
   "source": [
    "# single data point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2535b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateFeaturesSingle(sent,w,ind):\n",
    "    senWords=sent.split(' ')\n",
    "\n",
    "    corpusFeatures=defaultdict(list) #columns of final df\n",
    "\n",
    "    corpusFeatures['word'].append(w)\n",
    "    # corpusFeatures['word2'].append(w[-2:])\n",
    "    # corpusFeatures['word3'].append(w[-3:])\n",
    "    corpusFeatures['word3'].append(w[-4:])\n",
    "\n",
    "    digitOrPunct=0\n",
    "    for char in w:\n",
    "        if char.isdigit() or char in punctuation:\n",
    "            digitOrPunct=1\n",
    "    corpusFeatures['digitOrPunct'].append(digitOrPunct)\n",
    "\n",
    "    get_window=getWindow(senWords,ind)\n",
    "    preWord=get_window[0]\n",
    "    postWord=get_window[1]\n",
    "    corpusFeatures['preWord'].append(preWord)\n",
    "    corpusFeatures['postWord'].append(postWord)\n",
    "    \n",
    "    enLet='0'\n",
    "    if w in toFilter:\n",
    "        enLet='1'\n",
    "    corpusFeatures['engInitials'].append(enLet)\n",
    "\n",
    "    NER_feature='0'\n",
    "    for nerf in NERFeatures1:\n",
    "        if postWord.startswith(nerf):\n",
    "            NER_feature='1'\n",
    "    if NER_feature=='0':\n",
    "        for nerf in NERFeatures2:\n",
    "            if postWord.endswith(nerf):\n",
    "                NER_feature='1'\n",
    "    corpusFeatures['NERFeatures'].append(NER_feature)\n",
    "\n",
    "    isEnflg='1'\n",
    "    if w in totWordsIsEn.keys():\n",
    "            if totWordsIsEn[w]=='0':\n",
    "                isEnflg='0'\n",
    "    else:\n",
    "        isEnflg=isEnglish(siToEn(w))        \n",
    "    corpusFeatures['Translation'].append(isEnflg)\n",
    "\n",
    "    possibleSufs=[suf for suf in suffixes if w.endswith(suf)]\n",
    "    possibleSufs.sort(key=len, reverse=True)\n",
    "    if possibleSufs:\n",
    "        corpusFeatures['suffixes'].append(possibleSufs[0])\n",
    "    else:\n",
    "        corpusFeatures['suffixes'].append('None') \n",
    "                    \n",
    "    corpusFeatures['wordLen'].append((len(w)))\n",
    "\n",
    "    featureSetDf=createFeatureSetDf(corpusFeatures) \n",
    "    return featureSetDf\n",
    "\n",
    "def createFeatureSetDf(corpusFeatures):\n",
    "    featureSetDf=pd.DataFrame.from_dict(corpusFeatures,orient='index')\n",
    "    featureSetDf=featureSetDf.transpose()\n",
    "    #print(featureSetDf.head())\n",
    "\n",
    "    return featureSetDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43d9a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence='සේනාරත්න මහතා හදිසියේම කාර්යාලයට පැමිණියේය '\n",
    "word='සේනාරත්න'\n",
    "indx=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "01444e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "testFeatureSetDf=generateFeaturesSingle(sentence,word,indx)\n",
    "#trainFeatureSetDf=trainFeatureSetDf.fillna('0')\n",
    "x=ohe.transform(testFeatureSetDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6c9fb2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>word3</th>\n",
       "      <th>digitOrPunct</th>\n",
       "      <th>preWord</th>\n",
       "      <th>postWord</th>\n",
       "      <th>engInitials</th>\n",
       "      <th>NERFeatures</th>\n",
       "      <th>Translation</th>\n",
       "      <th>suffixes</th>\n",
       "      <th>wordLen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>සේනාරත්න</td>\n",
       "      <td>රත්න</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>මහතා</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>න</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       word word3 digitOrPunct preWord postWord engInitials NERFeatures  \\\n",
       "0  සේනාරත්න  රත්න            0             මහතා           0           1   \n",
       "\n",
       "  Translation suffixes wordLen  \n",
       "0           0        න       8  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testFeatureSetDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d34a0a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PER'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR.predict(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e6553d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56d738c7772affcbb9406b62ea03c3335d13b01087b0b22f0049ad34806b4a86"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
